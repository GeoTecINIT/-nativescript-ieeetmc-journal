---
title: "Reproducible package for 'Using mobile Devices as Scientific Measurement Instruments: Reliable Android Task Scheduling' - Experiment 1"
author: 
  - Alberto González, [GEOTEC research group](http://geotec.uji.es/), Universitat Jaume I of Castellón, Spain] 
  - Miguel Matey, [GEOTEC research group](http://geotec.uji.es/), Universitat Jaume I of Castellón, Spain]
  - Carlos Granell, [GEOTEC research group](http://geotec.uji.es/), Universitat Jaume I of Castellón, Spain] 
  - Sven Casteleyn, [GEOTEC research group](http://geotec.uji.es/), Universitat Jaume I of Castellón, Spain] 
date: "12/Mar/2021 (updated `r format(Sys.time(), '%d %B, %Y')`)"
output:
  html_document:
    df_print: paged
    number_sections: yes
    theme: readable
    toc: yes
    toc_depth: 4
    toc_float: yes
    code_folding: hide
  pdf_document:
    toc: yes
    toc_depth: 4

abstract: |
  This document analyses the reliability and scheduling performance of the self-developed library [NativeScript Task Dispatcher (NTD)](https://github.com/GeoTecINIT/nativescript-task-dispatcher) in a series of Android-based mobile devices as part of the [SyMptOMS project](http://geotec.uji.es/projects/SyMptOMS/). The main outcome of the paper is the NTD library. This notebook focuses on the results of the Experiment 1 (simple task scheduling), which are Table 1, Figure 4, Table 2, and Figure 5.

urlcolor: blue
---

```{r setup, include=FALSE, eval=TRUE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)
```

Required libraries and runtime environment description are as follows.

```{r load_libraries, echo=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(kableExtra)
library(here)
library(lubridate)
library(stringr)
library(scales)
library(grid)
library(gridBase)
library(gridExtra)
library(patchwork)
```

```{r set_seed}
# just in case
set.seed(nchar("Reproducible Package for 'Using mobile Devices as Scientific Measurement Instruments: Reliable Android Task Scheduling'"))
```

```{r rawdata_devices}

devices_file <- here::here("exp1", "data", "devices.csv")

cols(
   .default = readr::col_character(),
   id = readr::col_character(),
   device = readr::col_character(),
   os = readr::col_character(),
   exp_1 = readr::col_logical(),
   exp_2 = readr::col_logical()
) -> export_cols

devices <- readr::read_csv(
  file = devices_file, 
  col_names = TRUE, 
  trim_ws=TRUE,
  col_types = export_cols,
  na = "NA")

```

As reported in the paper, we deployed two applications to run the Experiment 1 (simple task scheduling): 1/ an ad-hoc application written in Java without an alarm watchdog, 2/ a NativeScript application that uses the NTD library. Both applications ran a simple recurrent task -- without logic or complex computations to produce a minimal execution overhead -- every minute for 2 weeks. We reused the data files generated in April/May 2020, whose file names start with the prefix `BA_` corresponds to the ad-hoc application (option 1). The data file names that start with `AD_` where created with the NTD-based application (option 2) in February 2021.

# Data preparation

```{r merge_datafiles_defs}

schedulers <- c("AD" = "NativeScript", 
                "BA" = "Ad-hoc")

baseline_delay <- 60
```

```{r merge_datafiles, eval=FALSE}

data_path <- here::here("exp1", "data-raw")
file_names <- list.files(path = data_path)
file_paths <- list.files(path = data_path, full.names = TRUE)

data_merged <- data.frame()


for (f in 1:length(file_names)) {
  filename <- stringr::str_sub(file_names[f], 1, 5)

  parts <- stringr::str_split(filename, "_", simplify = TRUE)
  
  scheduler_id = parts[1]
  scheduler_name <- schedulers[[scheduler_id]]
  device_id <- parts[2]
  device_name <- filter(devices, id == device_id) %>% select(device) %>% .$device
  device_desc <- paste0(scheduler_name, " - ", device_name)
  device_os <-  filter(devices, id == device_id) %>% select(os) %>% .$os
  
  data_temp <- read_csv(file_paths[f], col_names = TRUE, 
                        cols(
                          battery = col_double(),
                          exec_timestamp = col_double(),
                          planning_timestamp = col_double(),
                          task = col_character()
                        ))


  data_temp <- 
    data_temp %>%
    mutate(scheduler = scheduler_name,
           device_id = device_id,
           device_name = device_name,
           device_desc = device_desc,
           device_os = factor(device_os)) 
  
  data_merged <- rbind(data_merged, data_temp)
}       


data_merged <- 
  data_merged %>%
  select(-task) %>%
  mutate(exec_date = as_datetime(exec_timestamp/1000, tz="Europe/Madrid"),
         plan_date = as_datetime(planning_timestamp/1000, tz="Europe/Madrid"))
         

# Delay units: seconds
data_complete <-
  data_merged %>%
  group_by(device_id, scheduler) %>%
  arrange(exec_date) %>%
  mutate(step = row_number(),
         diff = exec_date - dplyr::lag(exec_date),
         diff_secs = as.numeric(diff, units = "secs"), 
         delay = diff_secs - baseline_delay)
      

data_path <- here::here("exp1", "data", "data_journal.csv")
write_csv(data_complete, data_path)
data_path <- here::here("exp1", "data", "data_journal.rds")
saveRDS(data_complete, data_path)

```


```{r load_assessdata, warning=FALSE}
assessment_file <- here::here("exp1", "data", "data_journal.rds")
data <- readRDS(assessment_file)

n_observations <- nrow(data) 

```

Raw data files are cleaned and merged together into a single file `exp1/data/data_ieeetmc`. Total observations: `r n_observations`. Key variables, as explained below, are computed too.

- quantitative (interval)

  - `plan_date` (*`r class(data$plan_date)`*): task planning time.
  - `exec_date` (*`r class(data$exec_date)`*): task execution time.\
  - `step`: relative position

- quantitative (ratio)

  - `diff` (*`r class(data$diff)`*): difference in seconds between the current and previous execution times.
  - `diff_secs` (*`r class(data$diff_secs)`*): numeric value of `diff`.
  - `delay` (*`r class(data$delay)`*): normalised execution delay in seconds (`diff_secs` - `r baseline_delay`).

- categorical (nominal)

  - `device_id`: device identifier
  - `device_name`: device name
  - `device_os`: Android OS version
  - `scheduler`: scheduler type

# Results 

## List of mobile devices for experimentation (Table 1 in the paper)

Below, the list of mobile devices used for both experiments. Here, we focus on Experiment 1.

```{r devices_table, echo=TRUE}

knitr::kable(devices %>%
               dplyr::select(ID = id, 
                             Device = device, 
                             `Android OS` = os, 
                             `Exp. 1` = exp_1, 
                             `Exp. 2` = exp_2),
             format = "html",
             booktabs = TRUE,
             caption = "TABLE 1. Mobile devices used for experimentation") %>%
  kableExtra::kable_styling(full_width = TRUE, bootstrap_options = c("condensed"))
      
```

## Reliability 

### Missingness of data

We compute the data loss ratio, i.e. the expected number of task executions against the real one. 

```{r missigness_prep}

data %>%
  dplyr::group_by(device_id, scheduler, device_os) %>%
  dplyr::arrange(step) %>%
  dplyr::summarise(n_real_exec = max(step),
                min_plan_date = min(plan_date),
                max_plan_date = max(plan_date),
                n_plan_exec = round(as.numeric(max_plan_date - min_plan_date, units="mins"))) %>%
  dplyr::select(device_id, scheduler, device_os, n_plan_exec, 
                n_real_exec, min_plan_date, max_plan_date) -> missingness


n_plan_exec_a1ba <- 20264 # every minute, during 2 weeks
n_plan_exec_nvba <- 20264
```

Devices *A1* and *NV* with the *Ad-hoc* scheduler did **not** end the experiment. The expected number of executions were `r format(n_plan_exec_a1ba, big.mark=',')` and `r format(n_plan_exec_nvba, big.mark=',')`, respectively.

```{r missigness_update}
missingness[1,c("n_plan_exec")] <- n_plan_exec_a1ba
missingness[7,c("n_plan_exec")] <- n_plan_exec_nvba
```

```{r missingness_percent}

missingness <-
  missingness %>%
  dplyr::mutate(percent = (1 - (n_real_exec / n_plan_exec)),
                percent_lbl = scales::percent(percent, accuracy = 0.01))
                
```

```{r missingness_table}
missingness$device_os <- forcats::fct_relevel(missingness$device_os, c("7.0", "8.1", "9.0"))

knitr::kable(missingness %>%
               select(`ID` = device_id,
                      `Scheduler` = scheduler,
                      `OS` = device_os,
                      `# planned executions` = n_plan_exec,
                      `# real executions` = n_real_exec,
                      `% missingness` = percent_lbl),
             format = "html",
             booktabs = TRUE,
             caption = "Missingness of task executions per device and scheduler.") %>%
  kableExtra::kable_styling(full_width = TRUE, bootstrap_options = c("striped", "bordered", "condensed"))

```

```{r missingness_means}

missingness_means <- 
  missingness %>% 
  dplyr::group_by(scheduler) %>% 
  dplyr::summarise(mean = mean(percent)) %>%
  dplyr::mutate(percent_mean = scales::percent(mean, accuracy = 0.1),
                lbl_mean = paste0(mean, " (", percent_mean, ")"))

knitr::kable(missingness_means %>%
               select(`Scheduler` = scheduler,
                      `Avg missingness (%)` = lbl_mean),
             format = "html",
             booktabs = TRUE,
             caption = "Average missingness of tak execution per type of scheduler.") %>%
    kableExtra::kable_styling(full_width = TRUE, bootstrap_options = c("striped", "bordered", "condensed"))
```

### Outliers


```{r}

limit_secs <- 10
data %>%
  dplyr::filter(abs(delay) >= limit_secs) %>%
  dplyr::select(scheduler, device_id, device_name, device_os, delay) -> outliers

```

We discard `r nrow(outliers)` out of `r format(n_observations, big.mark=",")` observations whose abs(`delay`) \>= `r limit_secs` seconds.

```{r delay_dataout}

data %>%
  dplyr::filter(abs(delay) < limit_secs) %>%
  dplyr::select(scheduler, device_id, device_name, device_os, delay) -> performance
```

### Boxplot to show delay distribution per device and type of application (Figure 4 in the paper)

`Delay` distribution per device and type of application. Percentage of missing task executions at the top (lower is better). Devices are sorted from the oldest to the newest version of Android. Green represents ad-hoc application, orange the NTD-based application.

```{r delay_boxplot_prep}

devices_ordered <- c("NV", "BQ", "A1", "H9") 
missingness_basic <- missingness %>% filter(scheduler == "Ad-hoc")
missingness_advanced <- missingness %>% filter(scheduler == "NativeScript")
devices_os <- 
  missingness %>% 
  dplyr::filter(scheduler == "NativeScript") %>% 
  dplyr::mutate(device_os_lbl = paste("Android", device_os)) %>%
  dplyr::select(device_id, device_os_lbl)

# Not run
# RColorBrewer::brewer.pal(n = 3, name="Dark2")[1:2]
# [1] "#1B9E77" "#D95F02"

```

```{r delay_boxplot, echo=TRUE, fig.height=5, fig.width=7, dpi=300}

performance %>%
  ggplot2::ggplot(aes(y = delay, x=device_id, color=scheduler)) +
  geom_boxplot(fill="white", outlier.fill = "white", outlier.alpha = 0.2) +
  
  scale_x_discrete(limits=devices_ordered) +
  scale_y_continuous(breaks=seq(-10,10,2)) +
  scale_color_brewer(palette = "Dark2") +
  # scale_color_grey(start = 0, end = 0.5) +
  
  geom_label(data = missingness_advanced, aes(x = device_id, y = 10, label = percent_lbl),
            color="#D95F02",
            size=4, nudge_y= 0.5,nudge_x = 0.2) +
  geom_label(data = missingness_basic, aes(x = device_id, y = 10, label = percent_lbl),
            color="#1B9E77", 
            size=4, nudge_y= 0.5,nudge_x = -0.2) +
  
  geom_label(data = devices_os, aes(x = device_id, y = -10, label = device_os_lbl), 
            color="grey30", size=4, nudge_y= 0.5,nudge_x = 0) +
  
  labs(title="", x ="Devices", y="Delay [seconds]") +
  ggplot2::guides(color=guide_legend(nrow = 2)) + 
  ggplot2::theme_minimal() +
  
  ggplot2::theme(axis.title.x = element_text(size = 13),
                 axis.title.y = element_text(size = 13),
                 strip.text.x = element_blank()) +
  
  # Add legend inside the plot
  ggplot2::theme(legend.title = element_blank(), 
        #  c(0,0) corresponds to the “bottom left” and c(1,1) to the “top right” position.
        legend.position = c(0.90, 0.20),
        legend.background = element_rect(color = "grey70", size = 0.2, linetype ="solid"),
        legend.key = element_blank()) -> p

p

ggplot2::ggsave(plot = p, filename = here::here("exp1", "figs", "fig_boxplot.png"), 
               width = 7, height = 5, dpi = 300)

```

### Histogram

Log scale distribution of `Delay` only for devices *BQ* and *H9*.

```{r delay_histogram, fig.height=14, fig.width=10, dpi=300}

performance %>%
  dplyr::filter(device_id %in% c("BQ", "H9")) %>% 
  ggplot2::ggplot(aes(x=delay, color=scheduler, fill=scheduler)) +
  ggplot2::geom_histogram(binwidth = 0.2,  alpha=0.5) + #4
  ggplot2::scale_color_brewer(palette = "Dark2") +
  ggplot2::scale_fill_brewer(palette = "Dark2") +
  ggplot2::scale_x_continuous(breaks=seq(-10,10,2)) +
  ggplot2::scale_y_log10(breaks = scales::trans_breaks("log10", function(x) 10^x),
                labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  
  ggplot2::facet_wrap(device_name~scheduler, ncol = 2, nrow = 2) +
  ggplot2::labs(title="", x ="Delay [seconds]", y="Frequency [log10]") +
  ggplot2::theme_minimal() + 
  
  ggplot2::theme(legend.title = element_blank(), 
                 legend.position = "none") -> p

p <- p + ggplot2::annotation_logticks(sides = "l")

p

```

## Performance overhead

To dig deeper into the scheduling performance of the BQ and H9 devices that successfully completed the experiment, we computed a new variable, **overhead** or `task_execution_delay`, as the difference between `exec_timestamp(n) - planning_timestamp(n+1)`. Due to the fact that `planning_timestamp(n+1)` is computed in the `n` task execution, this computation can reflect the overhead that the NTD introduces in the process caused by the complexity of the task planning and execution process based on alarm trigger. This complexity depends on the instructions set executed in each solution according to: 

- Instructions between [] do not count towards the **overhead** calculation or whose overhead cannot be calculated because they are executed before the `planning_timestamp` and after the `exec_timestamp`.

- Instructions starting with #1, #2 and #3() _do_ affect the **overhead**:
  - #1 are the instructions related to the acquisition and  storage of the `planning_timestamp`.
  - #2 are the instructions which happen between `planning_timestamp` and `exec_timestamp` acquisition.
  - #3 are the instructions related to the acquisition of the `exec_timestamp`.

Therefore, the NTD computes:

- [obtain next tasks to run from DB, calculate minimum interval and schedule next alarm] 
- #1 store `planning_timestamp` for next alarm trigger
- #2 obtain tasks to run now, calculate if service has to run in background or foreground, run the service, obtain tasks to run again (different context), build up task execution chains, trigger task chains.
- #3 store `exec_timestamp`
- [run first task of the first chain, second task, etc.]

The ad-hoc application computes:

- [schedule next alarm] 
- #1 store `planning_timestamp` for next alarm trigger
- #2 run the service, control that only one task is being executed at once) 
- #3 store `exec_timestamp` 
- [run task]


In both cases, #2 represents the instructions being run between the storage of the `planning_timestamp` of the next alarm and the storage of the `execution_timestamp` of the actual task. NTD encompasses a lot more instructions than the ad-hoc application.


```{r overhead_dataprep, warning=FALSE}

data %>%
  filter(device_id %in% c("H9", "BQ")) -> overhead


# Remove duplicated row by "plan_date" and keep the first occurrance
overhead <-
  overhead %>% dplyr::distinct(plan_date, .keep_all = TRUE)


#length(unique(overhead$plan_date) ) == nrow(overhead)


# overhead units: seconds
overhead <-
  overhead %>%
  group_by(device_id, scheduler) %>%
  arrange(plan_date) %>%
  mutate(task_execution_delay = exec_timestamp - dplyr::lead(planning_timestamp))


overhead %>%
  tidyr::drop_na(task_execution_delay) %>%
  filter(task_execution_delay > 0, task_execution_delay < 2000) -> overhead_clean

```

### Dropped values 

```{r overhead_values_dropped}

drop <- anti_join(overhead, overhead_clean) %>% select(device_id, scheduler, task_execution_delay)

n_drop = nrow(drop)

```
Values of `task_execution_delay` lesser than 2000 ms are retained for the analysis. In consequence, `r n_drop` are dropped due to invalid values of `task_execution_delay` as follows.

```{r overhead_values_dropped_table}

knitr::kable(drop,
             format = "html",
             booktabs = TRUE,
             caption = "TABLE. Dropped values") %>%
  kableExtra::kable_styling(full_width = TRUE, bootstrap_options = c("condensed")) %>%
  kableExtra::scroll_box(height = "300px")

```

### Overhead comparison per scheduler and device (Table 2 in the paper)

```{r overhead_table, echo=TRUE}
overhead_clean %>%
  dplyr::group_by(device_id, scheduler) %>%
  dplyr::summarise(task_execution_delay_min = min(task_execution_delay),
                   task_execution_delay_q1 = quantile(task_execution_delay, .25),
                   task_execution_delay_median = median(task_execution_delay),
                   task_execution_delay_mean = round(mean(task_execution_delay), 1),
                   task_execution_delay_q3 = quantile(task_execution_delay, .75),
                   task_execution_delay_max = max(task_execution_delay),
                   task_execution_delay_sd = round(sd(task_execution_delay), 1)) -> overhead_summaries

knitr::kable(t(overhead_summaries),
             format = "html",
             booktabs = TRUE,
             caption = "TABLE. Overhead comparison by device & scheduler (unit: ms)") %>%
  kableExtra::kable_styling(full_width = TRUE, bootstrap_options = c("condensed"))
      
```

### Overhead comparison per scheduler (Table 2 in the paper)

```{r overhead_per_scheduler_table, echo=TRUE}
overhead_clean %>%
  dplyr::group_by(scheduler) %>%
  dplyr::summarise(task_execution_delay_min = min(task_execution_delay),
                   task_execution_delay_q1 = quantile(task_execution_delay, .25, ),
                   task_execution_delay_median = median(task_execution_delay),
                   task_execution_delay_mean = round(mean(task_execution_delay), 1),
                   task_execution_delay_q3 = quantile(task_execution_delay, .75),
                   task_execution_delay_max = max(task_execution_delay),
                   task_execution_delay_sd = round(sd(task_execution_delay), 1)) -> overhead_summaries_scheduler

knitr::kable(t(overhead_summaries_scheduler),
             format = "html",
             booktabs = TRUE,
             caption = "TABLE. Overhead comparison per scheduler only (unit: ms)") %>%
  kableExtra::kable_styling(full_width = TRUE, bootstrap_options = c("condensed"))
```

Ad-hoc's average performance is `r overhead_summaries_scheduler$task_execution_delay_mean[1]` ms (sd = `r overhead_summaries_scheduler$task_execution_delay_sd[1]` ms), while NTD's is `r overhead_summaries_scheduler$task_execution_delay_mean[2]` ms (sd = `r overhead_summaries_scheduler$task_execution_delay_sd[2]` ms). On average, there is a __tiny performance penalty of `r overhead_summaries_scheduler$task_execution_delay_mean[2] - overhead_summaries_scheduler$task_execution_delay_mean[1]` ms against the NTD application__.


## Battery level


We look here if energy consumption is a barrier for the NTD application, compared to the less resource-demanding ad-hoc application. Again, we focus here only on the BQ and H9 devices that successfully completed the experiment.


### Battery level per 1-hour bin 

We computed battery level for each 1-hour bin, by selecting the first reading of the battery level in each hour. The plot below shows that the H9 device was also used for personal usage while executing the experiment of the Ad-hoc application. Therefore, we discard it and focus our attention on the BQ device, which was only used for experimentation.                 

```{r battery_dataprep, warning=FALSE}

data %>%
  filter(device_id %in%  c("H9", "BQ")) -> battery_data


battery_data <- 
  battery_data %>%
  mutate(plan_hour = lubridate::hour(plan_date),
         plan_day = lubridate::day(plan_date),
         plan_month = lubridate::month(plan_date))

battery_data %>%
  group_by(device_id, scheduler, plan_month, plan_day, plan_hour) %>%
  arrange(step) %>%
  dplyr::slice_head(n=1)  %>%
  ungroup() %>%
  group_by(device_id, scheduler) %>%
  mutate(bin = row_number()) %>%
  select(bin, plan_month, plan_day, plan_hour, battery, device_id, scheduler)  -> head_bin

```

```{r battery_plot, warning=FALSE, echo=TRUE}

head_bin %>%
  arrange(bin) %>%
  ggplot(aes(x=bin, y=battery, color=device_id)) +
  ggplot2::labs(title = "First reading of battery level per hour (1 hour = 1 bin)") +
  ggplot2::geom_line(size = 0.5) +
  ggplot2::facet_wrap(scheduler ~ device_id )

```


### BQ device’s hourly average battery consumption

```{r battery_offset_summaries, warning=FALSE, echo=TRUE}

head_bin %>% 
  filter(device_id == "BQ") %>%
  arrange(bin) %>%
  mutate(battery_offset = battery - lead(battery)) -> head_bin_bq

head_bin_bq %>%
  filter(battery_offset >= 0) %>%
  group_by(device_id, scheduler) %>%
  summarise(
    offset_mean = round(mean(battery_offset, na.rm=T), 2),
    offset_sd = round(sd(battery_offset, na.rm=T), 2)) -> head_bin_bq_summaries



knitr::kable(t(head_bin_bq_summaries),
             format = "html",
             booktabs = TRUE,
             caption = "TABLE. BQ's battery usage offset") %>%
  kableExtra::kable_styling(full_width = TRUE, bootstrap_options = c("condensed"))
        
```


### BQ's battery level offset

Here, we compute the BQ device's battery usage offset (last - fist battery reading) within a bin (1 bin = 1 hour).

```{r battery_offset_plot, warning=FALSE, echo=TRUE}


head_bin_bq %>%
  ggplot2::ggplot(aes(x=bin, y=battery_offset, color=scheduler)) +
  ggplot2::labs(
    # title = "BQ's battery offset (last - first reading) computed by hour (1 hour = 1 bin)",
    x = "", # Avoid duplication because it's pàrt of a composite plot
    y = "Battery usage offset by hour [%]") +
  ggplot2::geom_line(size = 0.5) +
  ggplot2::scale_color_brewer(palette = "Dark2") +
  ggplot2::scale_y_continuous(breaks=seq(-50,5,5)) +
  ggplot2::facet_wrap(~ scheduler) +
  ggplot2::theme_minimal() +
  ggplot2::theme(axis.text.x= element_text(size = 11), 
                 axis.text.y = element_text(size = 11),
                 axis.title.y = element_text(size = 14),
                 strip.text.x = element_text(size = 14)) +
  ggplot2::guides(color = FALSE) -> p_offset

p_offset

ggplot2::ggsave(plot = p_offset, filename = here::here("exp1", "figs", "fig_battery_usage.png"), 
               width = 7, height = 5, dpi = 300)

```


Here, we zoom in the BQ device's battery usage offset greater than zero to discard bins in which battery is being charged. This corresponds to Figure 5 in the paper.

```{r battery_offset_positive_plot}

head_bin_bq_summaries %>% select(scheduler, offset_mean, offset_sd) -> head_bin_bq_summaries_simplified


head_bin_bq %>%
  filter(battery_offset >= 0) %>%
  ggplot(aes(x=bin, y=battery_offset, color=scheduler)) +
  ggplot2::labs(
    # title = "BQ's battery offset (last - first reading) computed by hour (1 hour = 1 bin)",
    x = "Bins [1 bin = 1 hour]",
    y = "Battery usage offset by hour [%]") +
  ggplot2::geom_point(size = 1, alpha = 0.5, fill= "white" ) +
  ggplot2::scale_color_brewer(palette = "Dark2") +
  ggplot2::scale_y_continuous(breaks=seq(0,5,0.5)) +
  ggplot2::geom_hline(data = head_bin_bq_summaries_simplified, aes(yintercept = offset_mean, color=scheduler), alpha=0.5, size=1.5) +
  
  
  ggplot2::geom_text(data = head_bin_bq_summaries_simplified, aes(x = 170, 
                                                                  y = offset_mean, 
                                                                  label = paste0('mean=', offset_mean, ", ", "sd=", offset_sd),
                                                                  color=scheduler),
            size=5, nudge_y= 0.15,nudge_x = 0) +

  
  # ggplot2::geom_text(data = head_bin_bq_summaries_simplified, aes(x = 150, 
  #                                                                 y = offset_mean, 
  #                                                                 # https://stats.oarc.ucla.edu/r/codefragments/greek_letters/
  #                                                                 label = paste('mu', "==", offset_mean),
  #                                                                 color=scheduler),
  #           parse=TRUE, # Greek Symbols
  #           size=5, nudge_y= 0.15,nudge_x = 0) +
  # 
  # ggplot2::geom_text(data = head_bin_bq_summaries_simplified, aes(x = 210, 
  #                                                                 y = offset_mean, 
  #                                                                 # https://stats.oarc.ucla.edu/r/codefragments/greek_letters/
  #                                                                 label = paste('sigma', "==", offset_sd),
  #                                                                 color=scheduler),
  #           parse=TRUE, # Greek Symbols
  #           size=5, nudge_y= 0.15,nudge_x = 0) +
  
  
  # ggplot2::geom_smooth(method='lm', formula= y~x) +
  # ggpubr::stat_regline_equation(label.y = 3, label.x = 50, aes(label = ..eq.label..)) +
  # ggpubr::stat_regline_equation(label.y = 2.75, label.x = 50, aes(label = ..rr.label..)) +
  ggplot2::facet_wrap(~ scheduler) +
  
  ggplot2::theme_minimal() +
  ggplot2::theme(axis.text.x= element_text(size = 11), 
                 axis.text.y = element_text(size = 11), 
                 axis.title.x = element_text(size = 14),
                 axis.title.y = element_text(size = 14),
                 strip.text.x = element_blank()) +
  ggplot2::guides(color = FALSE) -> p_offset_lm
    
p_offset_lm

ggplot2::ggsave(plot = p_offset_lm, filename = here::here("exp1", "figs", "fig_battery_usage_wo_charging.png"), 
               width = 7, height = 5, dpi = 300)

```


### Composite plot to show BQ's battery usage (Figure 5 in the paper)

```{r battery_offset_composite, echo=TRUE, fig.height=9, fig.width=12}

fig_composite <- 
  p_offset / p_offset_lm + plot_annotation(
    subtitle = "")+
    # caption = "Data: BQ device") + 
  plot_annotation(tag_levels = 'A') &  
  theme(plot.tag = element_text(size = 11))

fig_composite

ggsave(fig_composite, file = here::here("exp1", "figs", "fig_battery_composite.png"), 
       width = 12, height = 9, dpi = 300)

```



Above plots remark that battery level offset is almost identical between the ad-hoc and NTD applications. On average, the NTD application uses `r head_bin_bq_summaries$offset_mean[2] - head_bin_bq_summaries$offset_mean[1]` more battery than the ad-hoc per hour. As a relative percentage, NTD uses `r percent(abs(1 - head_bin_bq_summaries$offset_mean[2] / head_bin_bq_summaries$offset_mean[1]))` more battery per hour than ad-hoc application. While percentage may look remarkable, it refers to tiny fractions of relative battery usage (< 0.1% per hour) .

